{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Baseline Models for Age and Gender Prediction from MEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += ['../']\n",
    "import matplotlib.pyplot as plt\n",
    "from src.data.preprocess import run_pca\n",
    "from src.data.make_dataset import load_dataset, load_subjects\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import hcp\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook provides an example of building a predictive model for the age and gender \n",
    "classification tasks from preprocessed MEG data. To run the examples you will need the\n",
    "preprocessed data downloaded from [link]() copied to the data folder in this repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MEG Data\n",
    "\n",
    "MEG data consists of around 250 channels of continuous signal data representing the output of the \n",
    "sensors placed around the head in the MEG.  Each channel picks up electrical activity at a position on\n",
    "the surface of the head.  Using advanced signal processing techniques we can localise some of this\n",
    "activity and identify where in the brain responses to certain stimuli or actios occur.  \n",
    "\n",
    "In these experiments we will be using __resting state recordings__ so no movement or events are\n",
    "involved.  The subject is just sitting and thinking and we expect a relatively __steady state signal__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Segmentation\n",
    "\n",
    "Our main dataset consists of around 95 subjects in three age categories (22-25, 26-30, 31-35).  The distribution\n",
    "is unbalanced so we have selected 16 subjects from each category for the training data.  Each subject has three\n",
    "recordings in the resting state and each is around 6 minutes long.  \n",
    "\n",
    "Making the assumption that these recordings represent a steady state, we have cut them up into 20s segments\n",
    "to create the target data for these experiments. Hence, our goal here is to build a model that can predict\n",
    "age or gender from a 20s segment of resting state MEG data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "There are a number of ways that we could generate features from these data segments. Recall that each\n",
    "segment consists of around 250 individual signals.  Assuming that these are steady state we have \n",
    "used an __averaged FFT spectrum__ for each channel.   This gives us a 24 point FFT for each channel\n",
    "in the data.   We have pre-computed these features for each segment and they are available in the downloaded preprocessed data directories.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analysis\n",
    "\n",
    "The first step is to load the dataset.  The file [hcp-train.csv](../data/hcp-train.csv) contains one\n",
    "row per subject along with their gender and age category labels.  Note, if you want to look at all\n",
    "of the subjects, [hcp-subjects.csv](../data/hcp-subjects.csv) contains all of their details.  \n",
    "\n",
    "We will then create feature vectors from the raw array data.  We do this here by selecting the first\n",
    "ten channels and concatenating them to give a 240 element feature vector for each recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def transform_data(data, channels):\n",
    "    \"\"\"Select a number of channels from each data record and concatenate them into a single vector\"\"\"\n",
    "    \n",
    "    return [np.ravel(d[0][:channels]) for d in data['data']]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('../data/processed/hcp', '../data/hcp-train.csv')\n",
    "channels = 10\n",
    "dd = transform_data(dataset, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualisation\n",
    "\n",
    "We can define a simple visualisation of the data to get an idea of what we are working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def show(n):\n",
    "    data = dd[n]\n",
    "    data = data.reshape(channels,24)\n",
    "    plt.pcolor(data)\n",
    "    print(dataset['age'][n], dataset['gender'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22-25 F\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26-30 F\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31-35 F\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(2001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Baseline Model\n",
    "\n",
    "For a baseline we define a simple support vector machine model and train on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_model = svm.SVC(gamma=0.01, C=10.)\n",
    "age_model.fit(dd, dataset['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, key, data, ref):\n",
    "    predicted = model.predict(data)\n",
    "    print(\"{:.2f}% correct\".format(100*accuracy_score(ref[key], predicted)))\n",
    "    print(confusion_matrix(ref[key], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.96% correct\n",
      "[[815   0   0]\n",
      " [  0 822   0]\n",
      " [  0   1 867]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(age_model, 'age', dd, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predicting Gender\n",
    "\n",
    "We can repeat the process to predict gender using a similar model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_model = svm.SVC(gamma=0.01, C=10.)\n",
    "gender_model.fit(dd, dataset['gender'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% correct\n",
      "[[ 931    0]\n",
      " [   0 1574]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(gender_model, 'gender', dd, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "For evaluation we have withheld 11 subjects. Their identifiers are in [hcp-eval-dist.csv](../data/hcp-eval-dist.csv).  To evaluate our model, we load these subjects in the same way as the original data.  To evaluate the model we will generate the predicted age category labels for each entry and write them to a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "testdataset = load_dataset('../data/processed/hcp', '../data/hcp-eval-dist.csv')\n",
    "channels = 10\n",
    "td = transform_data(testdataset, channels)\n",
    "\n",
    "age = age_model.predict(td)\n",
    "gender = gender_model.predict(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391631-15-1</td>\n",
       "      <td>31-35</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>391631-15-0</td>\n",
       "      <td>31-35</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>391631-17-2</td>\n",
       "      <td>26-30</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>391631-17-0</td>\n",
       "      <td>31-35</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>391631-15-2</td>\n",
       "      <td>31-35</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    age gender\n",
       "0  391631-15-1  31-35      F\n",
       "1  391631-15-0  31-35      F\n",
       "2  391631-17-2  26-30      F\n",
       "3  391631-17-0  31-35      F\n",
       "4  391631-15-2  31-35      F"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df = pd.DataFrame({'id': testdataset['id'], 'age': age, 'gender': gender})\n",
    "predicted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generating your own Features\n",
    "\n",
    "We've written code to process the MEG data using the [MNE](https://mne.tools/) package.  You can \n",
    "use this as the basis of your own preprocessinng if you want to use different features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def read_hcp(subject: str, data_folder: str, run_index: int) -> mne.io.Raw:\n",
    "    \"\"\"\n",
    "    Read a data file from the HCP dataset, return a Raw instance\n",
    "    \"\"\"\n",
    "\n",
    "    raw = hcp.read_raw(subject=subject, data_type='rest', hcp_path=data_folder, run_index=run_index)\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def spectral_epochs(label: str, raw: mne.io.Raw, epoch_size: int, max_freq: int = 100, n_fft: int = 48) -> np.array: \n",
    "    \"\"\"Read raw data and split into epochs of a given size (s), compute features\n",
    "    over each one\n",
    "    label: subject identifier\n",
    "    epoch_size: duration of epochs in seconds\n",
    "    data_folder: location of source data\n",
    "    max_freq: max frequency for FFT (default 100)\n",
    "    n_fft: FFT size (default 48)\n",
    "\n",
    "    Returns: labels, features\n",
    "    labels: a list of labels with the format <subject>-<run_index>-<N>\n",
    "    features: a list of np.arrays one per epoch containing the features\n",
    "    \"\"\"\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    events = mne.make_fixed_length_events(raw, id=1, duration=epoch_size)\n",
    "    epochs = mne.Epochs(raw, events, tmin=0., tmax=epoch_size, baseline=None,\n",
    "                        detrend=1, decim=8, preload=True)\n",
    "\n",
    "    for N in range(len(epochs)):\n",
    "        features.append(spectral_features(epochs[N], max_freq=max_freq, n_fft=n_fft))\n",
    "        labels.append(\"{}-{}\".format(label, N))\n",
    "        print('.', end='', flush=True)\n",
    "    print('|', end='', flush=True)        \n",
    "    return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def spectral_features(raw: mne.io.Raw, max_freq: int = 100, n_fft: int = 48) -> np.array: \n",
    "    \"\"\"Compute flattened spectral features given a cropped raw recording.\n",
    "\n",
    "    Data is low-pass filtered to max_freq (default 100Hz) and downsampled to 2*max_freq before features are\n",
    "    computed. \n",
    "\n",
    "    Computes a n_fft (default 48) point FFT. Takes the log to compute the final features which\n",
    "    are then concatenated into a one dimensional feature vector.\n",
    "\n",
    "    Returns a N x 24 np.array where N is the number of channels\"\"\"\n",
    "\n",
    "    raw.filter(None, max_freq, h_trans_bandwidth=0.5, filter_length='10s', phase='zero-double', fir_design='firwin2')\n",
    "    raw.resample(2*max_freq, npad=\"auto\")\n",
    "\n",
    "    psds, _freqs = mne.time_frequency.psd_welch(raw, fmin=1, n_fft=n_fft)\n",
    "\n",
    "    return np.log(psds)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
